{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf1945e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-01T16:11:40.045316Z",
     "iopub.status.busy": "2024-07-01T16:11:40.044931Z",
     "iopub.status.idle": "2024-07-01T16:11:57.689176Z",
     "shell.execute_reply": "2024-07-01T16:11:57.687409Z"
    },
    "papermill": {
     "duration": 17.657017,
     "end_time": "2024-07-01T16:11:57.691656",
     "exception": false,
     "start_time": "2024-07-01T16:11:40.034639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\r\n",
      "Collecting scikit-learn\r\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\r\n",
      "Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.5.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c15671",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:11:57.711340Z",
     "iopub.status.busy": "2024-07-01T16:11:57.710905Z",
     "iopub.status.idle": "2024-07-01T16:12:00.849036Z",
     "shell.execute_reply": "2024-07-01T16:12:00.848020Z"
    },
    "papermill": {
     "duration": 3.151006,
     "end_time": "2024-07-01T16:12:00.851726",
     "exception": false,
     "start_time": "2024-07-01T16:11:57.700720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2e66f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:00.871658Z",
     "iopub.status.busy": "2024-07-01T16:12:00.871092Z",
     "iopub.status.idle": "2024-07-01T16:12:00.876060Z",
     "shell.execute_reply": "2024-07-01T16:12:00.874894Z"
    },
    "papermill": {
     "duration": 0.017486,
     "end_time": "2024-07-01T16:12:00.878205",
     "exception": false,
     "start_time": "2024-07-01T16:12:00.860719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_JOBS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6167ddcd",
   "metadata": {
    "papermill": {
     "duration": 0.008334,
     "end_time": "2024-07-01T16:12:00.895384",
     "exception": false,
     "start_time": "2024-07-01T16:12:00.887050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d9e6f47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:00.914129Z",
     "iopub.status.busy": "2024-07-01T16:12:00.913714Z",
     "iopub.status.idle": "2024-07-01T16:12:02.731743Z",
     "shell.execute_reply": "2024-07-01T16:12:02.730553Z"
    },
    "papermill": {
     "duration": 1.830434,
     "end_time": "2024-07-01T16:12:02.734346",
     "exception": false,
     "start_time": "2024-07-01T16:12:00.903912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378428, 13) (252286, 12)\n"
     ]
    }
   ],
   "source": [
    "training_data_path = '../input/ml-competition-2024-for-ukrainians/train.csv'\n",
    "test_data_path = '../input/ml-competition-2024-for-ukrainians/test.csv'\n",
    "train_df = pd.read_csv(training_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5d204b",
   "metadata": {
    "papermill": {
     "duration": 0.008767,
     "end_time": "2024-07-01T16:12:02.752849",
     "exception": false,
     "start_time": "2024-07-01T16:12:02.744082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81dcf0dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:02.772039Z",
     "iopub.status.busy": "2024-07-01T16:12:02.771634Z",
     "iopub.status.idle": "2024-07-01T16:12:02.807064Z",
     "shell.execute_reply": "2024-07-01T16:12:02.805769Z"
    },
    "papermill": {
     "duration": 0.047693,
     "end_time": "2024-07-01T16:12:02.809327",
     "exception": false,
     "start_time": "2024-07-01T16:12:02.761634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_visibility: 0.06264653074731183\n"
     ]
    }
   ],
   "source": [
    "def process_visibility(train_df, test_df):\n",
    "    train_df[\"Item_Visibility\"] = train_df[\"Item_Visibility\"].replace(0, np.nan)\n",
    "    test_df[\"Item_Visibility\"] = test_df[\"Item_Visibility\"].replace(0, np.nan)\n",
    "\n",
    "    train_df[\"Item_Visibility\"] = np.log1p(train_df[\"Item_Visibility\"])\n",
    "    test_df[\"Item_Visibility\"] = np.log1p(test_df[\"Item_Visibility\"])\n",
    "\n",
    "    mean_visibility = train_df[\"Item_Visibility\"].mean()\n",
    "    print(f\"mean_visibility: {mean_visibility}\")\n",
    "\n",
    "    train_df[\"Item_Visibility\"] = train_df[\"Item_Visibility\"].fillna(mean_visibility)\n",
    "    test_df[\"Item_Visibility\"] = test_df[\"Item_Visibility\"].fillna(mean_visibility)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = process_visibility(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3c2226d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:02.829574Z",
     "iopub.status.busy": "2024-07-01T16:12:02.828900Z",
     "iopub.status.idle": "2024-07-01T16:12:02.842291Z",
     "shell.execute_reply": "2024-07-01T16:12:02.841027Z"
    },
    "papermill": {
     "duration": 0.025792,
     "end_time": "2024-07-01T16:12:02.844824",
     "exception": false,
     "start_time": "2024-07-01T16:12:02.819032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df[\"Item_Outlet_Sales\"] = np.log1p(train_df[\"Item_Outlet_Sales\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9840ca12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:02.864835Z",
     "iopub.status.busy": "2024-07-01T16:12:02.864435Z",
     "iopub.status.idle": "2024-07-01T16:12:02.876305Z",
     "shell.execute_reply": "2024-07-01T16:12:02.874998Z"
    },
    "papermill": {
     "duration": 0.024427,
     "end_time": "2024-07-01T16:12:02.878575",
     "exception": false,
     "start_time": "2024-07-01T16:12:02.854148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_mean: 7.360180293004388, target_std: 0.8535593658882088\n"
     ]
    }
   ],
   "source": [
    "target_mean = train_df[\"Item_Outlet_Sales\"].mean()\n",
    "target_std = train_df[\"Item_Outlet_Sales\"].std()\n",
    "print(f\"target_mean: {target_mean}, target_std: {target_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab408f02",
   "metadata": {
    "papermill": {
     "duration": 0.008805,
     "end_time": "2024-07-01T16:12:02.896564",
     "exception": false,
     "start_time": "2024-07-01T16:12:02.887759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8098d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:02.916812Z",
     "iopub.status.busy": "2024-07-01T16:12:02.915849Z",
     "iopub.status.idle": "2024-07-01T16:12:02.923600Z",
     "shell.execute_reply": "2024-07-01T16:12:02.922388Z"
    },
    "papermill": {
     "duration": 0.020665,
     "end_time": "2024-07-01T16:12:02.926317",
     "exception": false,
     "start_time": "2024-07-01T16:12:02.905652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_Item_Fat_Content(x):\n",
    "    if x == \"LF\" or x == \"low fat\":\n",
    "        return \"Low Fat\"\n",
    "    elif x == \"reg\":\n",
    "        return \"Regular\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def mrp2class(v):\n",
    "    b0 = 70\n",
    "    b1 = 135\n",
    "    b2 = 204\n",
    "    if v < b0:\n",
    "        return 0\n",
    "    elif v >= b0 and v < b1:\n",
    "        return 1\n",
    "    elif v >= b1 and v < b2:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def extract_features(df):\n",
    "    df[\"Item_Fat_Content\"] = df[\"Item_Fat_Content\"].apply(lambda x: clean_Item_Fat_Content(x))\n",
    "    df[\"Item_MRP_class\"] = df[\"Item_MRP\"].apply(lambda x: mrp2class(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37fb9e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:02.947343Z",
     "iopub.status.busy": "2024-07-01T16:12:02.946916Z",
     "iopub.status.idle": "2024-07-01T16:12:03.605154Z",
     "shell.execute_reply": "2024-07-01T16:12:03.604146Z"
    },
    "papermill": {
     "duration": 0.671606,
     "end_time": "2024-07-01T16:12:03.608122",
     "exception": false,
     "start_time": "2024-07-01T16:12:02.936516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "extract_features(train_df)\n",
    "extract_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fe844",
   "metadata": {
    "papermill": {
     "duration": 0.008822,
     "end_time": "2024-07-01T16:12:03.626419",
     "exception": false,
     "start_time": "2024-07-01T16:12:03.617597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6e1df8",
   "metadata": {
    "papermill": {
     "duration": 0.008763,
     "end_time": "2024-07-01T16:12:03.644414",
     "exception": false,
     "start_time": "2024-07-01T16:12:03.635651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f0bfd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:03.664394Z",
     "iopub.status.busy": "2024-07-01T16:12:03.663987Z",
     "iopub.status.idle": "2024-07-01T16:12:03.673282Z",
     "shell.execute_reply": "2024-07-01T16:12:03.672150Z"
    },
    "papermill": {
     "duration": 0.022112,
     "end_time": "2024-07-01T16:12:03.675730",
     "exception": false,
     "start_time": "2024-07-01T16:12:03.653618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def target_encode_cv(train_df, test_df, target_column, categorical_column, n_splits=5):\n",
    "    \"\"\"\n",
    "    Encodes a categorical variable with the mean of the target variable using cross-validation to avoid target leakage.\n",
    "\n",
    "    :param train_df: pandas DataFrame containing the training data\n",
    "    :param test_df: pandas DataFrame containing the test data\n",
    "    :param target_column: name of the target column in the training data\n",
    "    :param categorical_column: name of the categorical column to be encoded\n",
    "    :param n_splits: number of splits for cross-validation\n",
    "    :return: Two DataFrames with the new encoded feature added to both train and test data\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    train_df[f'{categorical_column}_TE'] = np.nan\n",
    "    \n",
    "    # Create a temporary DataFrame for test encoding\n",
    "    test_encoded = pd.DataFrame()\n",
    "    \n",
    "    for train_index, val_index in kf.split(train_df):\n",
    "        X_train, X_val = train_df.iloc[train_index], train_df.iloc[val_index]\n",
    "        \n",
    "        # Compute the mean of the target for each category in the training fold\n",
    "        category_target_mean = X_train.groupby(categorical_column)[target_column].mean()\n",
    "        \n",
    "        # Map the means to the validation fold\n",
    "        train_df.loc[train_df.index[val_index], f'{categorical_column}_TE'] = \\\n",
    "            train_df.loc[train_df.index[val_index], categorical_column].map(category_target_mean)\n",
    "        \n",
    "        # Update test encoding by accumulating results from each fold\n",
    "        fold_test_encoded = test_df[categorical_column].map(category_target_mean)\n",
    "        test_encoded = pd.concat([test_encoded, fold_test_encoded], axis=1)\n",
    "    \n",
    "    # Compute the mean for test encoding over all folds\n",
    "    test_df[f'{categorical_column}_TE'] = test_encoded.mean(axis=1)\n",
    "    \n",
    "    # Handle missing values in test set that were not present in training set\n",
    "    test_df[f'{categorical_column}_TE'].fillna(train_df[target_column].mean(), inplace=True)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fffb119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:03.695821Z",
     "iopub.status.busy": "2024-07-01T16:12:03.694952Z",
     "iopub.status.idle": "2024-07-01T16:12:07.866860Z",
     "shell.execute_reply": "2024-07-01T16:12:07.865755Z"
    },
    "papermill": {
     "duration": 4.184677,
     "end_time": "2024-07-01T16:12:07.869502",
     "exception": false,
     "start_time": "2024-07-01T16:12:03.684825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18/1988439080.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[f'{categorical_column}_TE'].fillna(train_df[target_column].mean(), inplace=True)\n",
      "/tmp/ipykernel_18/1988439080.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[f'{categorical_column}_TE'].fillna(train_df[target_column].mean(), inplace=True)\n",
      "/tmp/ipykernel_18/1988439080.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[f'{categorical_column}_TE'].fillna(train_df[target_column].mean(), inplace=True)\n",
      "/tmp/ipykernel_18/1988439080.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[f'{categorical_column}_TE'].fillna(train_df[target_column].mean(), inplace=True)\n",
      "/tmp/ipykernel_18/1988439080.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[f'{categorical_column}_TE'].fillna(train_df[target_column].mean(), inplace=True)\n",
      "/tmp/ipykernel_18/1988439080.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df[f'{categorical_column}_TE'].fillna(train_df[target_column].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "te_cols = []\n",
    "cols_for_te = [\n",
    "    \"Item_Identifier\",\n",
    "    \"Item_Type\",\n",
    "    \"Outlet_Identifier\",\n",
    "    \"Item_MRP\",\n",
    "    \"Item_Weight\",\n",
    "    \"Item_Visibility\",\n",
    "]\n",
    "for c in cols_for_te:\n",
    "    train_df, test_df = target_encode_cv(train_df, test_df, \"Item_Outlet_Sales\", c)\n",
    "    te_cols.append(f\"{c}_TE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1677e9",
   "metadata": {
    "papermill": {
     "duration": 0.009275,
     "end_time": "2024-07-01T16:12:07.892432",
     "exception": false,
     "start_time": "2024-07-01T16:12:07.883157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Frequency encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2532213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:07.912896Z",
     "iopub.status.busy": "2024-07-01T16:12:07.912521Z",
     "iopub.status.idle": "2024-07-01T16:12:07.919176Z",
     "shell.execute_reply": "2024-07-01T16:12:07.918135Z"
    },
    "papermill": {
     "duration": 0.019405,
     "end_time": "2024-07-01T16:12:07.921444",
     "exception": false,
     "start_time": "2024-07-01T16:12:07.902039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def frequency_encoding(train_df, test_df, categorical_columns):\n",
    "    \"\"\"\n",
    "    Perform frequency encoding for the specified categorical columns in the train and test dataframes.\n",
    "\n",
    "    Args:\n",
    "    train_df (pd.DataFrame): The training dataframe containing categorical columns to encode.\n",
    "    test_df (pd.DataFrame): The test dataframe containing categorical columns to encode.\n",
    "    categorical_columns (list): A list of column names to apply frequency encoding on.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.DataFrame: The train and test dataframes with the specified categorical columns frequency encoded.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_df_encoded = train_df.copy()  # Make a copy of the training dataframe to avoid modifying the original one\n",
    "    test_df_encoded = test_df.copy()    # Make a copy of the test dataframe to avoid modifying the original one\n",
    "    \n",
    "    for column in categorical_columns:\n",
    "        freq_map = train_df[column].value_counts().to_dict()  # Calculate the frequency of each category from the training data\n",
    "        train_df_encoded[column + \"_FE\"] = train_df[column].map(freq_map)  # Map the frequencies to the original column values in the training data\n",
    "        test_df_encoded[column + \"_FE\"] = test_df[column].map(freq_map).fillna(0)  # Map the frequencies to the original column values in the test data, filling NaN with 0\n",
    "    \n",
    "    return train_df_encoded, test_df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a3dd7db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:07.942320Z",
     "iopub.status.busy": "2024-07-01T16:12:07.941931Z",
     "iopub.status.idle": "2024-07-01T16:12:08.584653Z",
     "shell.execute_reply": "2024-07-01T16:12:08.583465Z"
    },
    "papermill": {
     "duration": 0.65619,
     "end_time": "2024-07-01T16:12:08.587237",
     "exception": false,
     "start_time": "2024-07-01T16:12:07.931047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fe_cols = [\n",
    "    \"Item_Identifier\",\n",
    "    \"Item_Type\",\n",
    "    \"Outlet_Identifier\",\n",
    "    \"Item_MRP\",\n",
    "    \"Item_Weight\",\n",
    "    \"Item_Visibility\",\n",
    "]\n",
    "train_df, test_df = frequency_encoding(train_df, test_df, fe_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d775b1",
   "metadata": {
    "papermill": {
     "duration": 0.009248,
     "end_time": "2024-07-01T16:12:08.606285",
     "exception": false,
     "start_time": "2024-07-01T16:12:08.597037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Interaction-based encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5005799c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:08.627240Z",
     "iopub.status.busy": "2024-07-01T16:12:08.626821Z",
     "iopub.status.idle": "2024-07-01T16:12:08.635707Z",
     "shell.execute_reply": "2024-07-01T16:12:08.634667Z"
    },
    "papermill": {
     "duration": 0.022115,
     "end_time": "2024-07-01T16:12:08.637891",
     "exception": false,
     "start_time": "2024-07-01T16:12:08.615776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interaction_based_encoding(train_df, test_df, categorical_column, numerical_column, target_column, n_splits=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Perform Interaction-Based Encoding for a specified categorical and numerical column using K-Fold cross-validation to avoid target leakage.\n",
    "\n",
    "    :param train_df: pandas DataFrame containing the training data.\n",
    "    :param test_df: pandas DataFrame containing the test data.\n",
    "    :param categorical_column: The name of the categorical column to encode.\n",
    "    :param numerical_column: The name of the numerical column to interact with.\n",
    "    :param target_column: The name of the target column.\n",
    "    :param n_splits: Number of splits for K-Fold cross-validation.\n",
    "    :param random_state: Random state for reproducibility.\n",
    "    :return: Tuple of encoded training and test DataFrames.\n",
    "    \"\"\"\n",
    "    # Initialize the KFold cross-validator\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    # Initialize an empty array to hold the encoded values\n",
    "    train_encoded = np.zeros(len(train_df))\n",
    "    \n",
    "    # Perform K-Fold cross-validation\n",
    "    for train_index, val_index in kf.split(train_df):\n",
    "        train_fold, val_fold = train_df.iloc[train_index], train_df.iloc[val_index]\n",
    "        \n",
    "        # Calculate the mean of the numerical column for each category in the training fold\n",
    "        category_stats = train_fold.groupby(categorical_column)[numerical_column].mean()\n",
    "        \n",
    "        # Create a dictionary for quick lookup\n",
    "        category_mean_dict = category_stats.to_dict()\n",
    "        \n",
    "        # Encode the validation fold using the training fold's category stats\n",
    "        val_fold_encoded = val_fold[categorical_column].map(category_mean_dict).fillna(train_df[numerical_column].mean())\n",
    "        train_encoded[val_index] = val_fold_encoded\n",
    "    \n",
    "    # Assign the encoded values back to the training DataFrame\n",
    "    train_df[categorical_column + '_IE_' + numerical_column] = train_encoded\n",
    "    \n",
    "    # Calculate the category statistics for the entire training set to encode the test set\n",
    "    category_stats = train_df.groupby(categorical_column)[numerical_column].mean()\n",
    "    category_mean_dict = category_stats.to_dict()\n",
    "    \n",
    "    # Encode the test data (handling unknown categories by assigning them the global mean of the numerical column)\n",
    "    test_encoded = test_df[categorical_column].map(category_mean_dict).fillna(train_df[numerical_column].mean())\n",
    "    test_df[categorical_column + '_IE_' + numerical_column] = test_encoded\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "999bad7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:08.659605Z",
     "iopub.status.busy": "2024-07-01T16:12:08.658719Z",
     "iopub.status.idle": "2024-07-01T16:12:14.981129Z",
     "shell.execute_reply": "2024-07-01T16:12:14.979946Z"
    },
    "papermill": {
     "duration": 6.336121,
     "end_time": "2024-07-01T16:12:14.983676",
     "exception": false,
     "start_time": "2024-07-01T16:12:08.647555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ie_col_pairs = [\n",
    "    (\"Item_Identifier\", \"Item_MRP\"),\n",
    "    (\"Item_Identifier\", \"Item_Weight\"),\n",
    "    (\"Item_Identifier\", \"Item_Visibility\"),\n",
    "    (\"Item_Type\", \"Item_MRP\"),\n",
    "    (\"Item_Type\", \"Item_Weight\"),\n",
    "    (\"Item_Type\", \"Item_Visibility\"),\n",
    "    (\"Outlet_Identifier\", \"Item_MRP\"),\n",
    "    (\"Outlet_Identifier\", \"Item_Weight\"),\n",
    "    (\"Outlet_Identifier\", \"Item_Visibility\"),\n",
    "]\n",
    "ie_cols = []\n",
    "for cat_c, num_c in ie_col_pairs:\n",
    "    train_df, test_df = interaction_based_encoding(train_df, test_df, cat_c, num_c, \"Item_Outlet_Sales\")\n",
    "    ie_cols.append(cat_c + \"_IE_\" + num_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd51daf0",
   "metadata": {
    "papermill": {
     "duration": 0.009177,
     "end_time": "2024-07-01T16:12:15.003056",
     "exception": false,
     "start_time": "2024-07-01T16:12:14.993879",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01129515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:15.024124Z",
     "iopub.status.busy": "2024-07-01T16:12:15.023723Z",
     "iopub.status.idle": "2024-07-01T16:12:19.607900Z",
     "shell.execute_reply": "2024-07-01T16:12:19.606894Z"
    },
    "papermill": {
     "duration": 4.59761,
     "end_time": "2024-07-01T16:12:19.610241",
     "exception": false,
     "start_time": "2024-07-01T16:12:15.012631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LE: Item_Identifier\n",
      "LE: Item_Fat_Content\n",
      "LE: Item_Type\n",
      "LE: Outlet_Identifier\n",
      "LE: Outlet_Size\n",
      "LE: Outlet_Location_Type\n",
      "LE: Outlet_Type\n",
      "(378428, 35) (252286, 34)\n"
     ]
    }
   ],
   "source": [
    "def label_encode(train_df, test_df):\n",
    "    label_encoders = {}\n",
    "    cat_cols = []\n",
    "    for column in train_df.columns:\n",
    "        if train_df[column].dtype == 'object' or train_df[column].dtype == 'category':\n",
    "            print(f\"LE: {column}\")\n",
    "            le = LabelEncoder()\n",
    "            # Fit on both training and test data to ensure consistency\n",
    "            le.fit(list(train_df[column].astype(str)) + list(test_df[column].astype(str)))\n",
    "            train_df[column] = le.transform(train_df[column].astype(str))\n",
    "            test_df[column] = le.transform(test_df[column].astype(str))\n",
    "            label_encoders[column] = le\n",
    "            cat_cols.append(column)\n",
    "    return train_df, test_df, label_encoders, cat_cols\n",
    "\n",
    "# Apply label encoding\n",
    "train_df, test_df, _, cat_cols = label_encode(train_df, test_df)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c76ed",
   "metadata": {
    "papermill": {
     "duration": 0.009867,
     "end_time": "2024-07-01T16:12:19.630158",
     "exception": false,
     "start_time": "2024-07-01T16:12:19.620291",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare data for tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41902e75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:19.651441Z",
     "iopub.status.busy": "2024-07-01T16:12:19.651056Z",
     "iopub.status.idle": "2024-07-01T16:12:20.017934Z",
     "shell.execute_reply": "2024-07-01T16:12:20.016810Z"
    },
    "papermill": {
     "duration": 0.380654,
     "end_time": "2024-07-01T16:12:20.020749",
     "exception": false,
     "start_time": "2024-07-01T16:12:19.640095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_train_features.shape: (378428, 27), tree_test_features.shape: (252286, 27)\n",
      "tree_train_features.columns: ['Item_Identifier' 'Item_Weight' 'Item_Visibility' 'Item_Type' 'Item_MRP'\n",
      " 'Outlet_Identifier' 'Item_Identifier_TE' 'Item_Type_TE'\n",
      " 'Outlet_Identifier_TE' 'Item_MRP_TE' 'Item_Weight_TE'\n",
      " 'Item_Visibility_TE' 'Item_Identifier_FE' 'Item_Type_FE'\n",
      " 'Outlet_Identifier_FE' 'Item_MRP_FE' 'Item_Weight_FE'\n",
      " 'Item_Visibility_FE' 'Item_Identifier_IE_Item_MRP'\n",
      " 'Item_Identifier_IE_Item_Weight' 'Item_Identifier_IE_Item_Visibility'\n",
      " 'Item_Type_IE_Item_MRP' 'Item_Type_IE_Item_Weight'\n",
      " 'Item_Type_IE_Item_Visibility' 'Outlet_Identifier_IE_Item_MRP'\n",
      " 'Outlet_Identifier_IE_Item_Weight' 'Outlet_Identifier_IE_Item_Visibility']\n"
     ]
    }
   ],
   "source": [
    "tree_drop_cols=[\n",
    "    \"id\", # ID\n",
    "    \"Item_Outlet_Sales\", # TARGET\n",
    "    \"Outlet_Establishment_Year\",\n",
    "    \"Item_Fat_Content\",\n",
    "    \"Outlet_Size\",\n",
    "    \"Outlet_Location_Type\",\n",
    "    \"Outlet_Type\",\n",
    "    \"Item_MRP_class\",\n",
    "]\n",
    "\n",
    "tree_train_features = train_df.drop(columns=tree_drop_cols, errors=\"ignore\")\n",
    "target = train_df['Item_Outlet_Sales'].values\n",
    "\n",
    "# Handling missing values\n",
    "features_mean = tree_train_features.mean()\n",
    "tree_train_features = tree_train_features.fillna(features_mean)\n",
    "tree_test_features = test_df.drop(columns=tree_drop_cols, errors=\"ignore\").fillna(features_mean)\n",
    "\n",
    "print(f\"tree_train_features.shape: {tree_train_features.shape}, tree_test_features.shape: {tree_test_features.shape}\")\n",
    "print(f\"tree_train_features.columns: {tree_train_features.columns.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6354ea18",
   "metadata": {
    "papermill": {
     "duration": 0.010039,
     "end_time": "2024-07-01T16:12:20.041289",
     "exception": false,
     "start_time": "2024-07-01T16:12:20.031250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare data for linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1945fd73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:20.062740Z",
     "iopub.status.busy": "2024-07-01T16:12:20.062330Z",
     "iopub.status.idle": "2024-07-01T16:12:22.022241Z",
     "shell.execute_reply": "2024-07-01T16:12:22.020951Z"
    },
    "papermill": {
     "duration": 1.973323,
     "end_time": "2024-07-01T16:12:22.024592",
     "exception": false,
     "start_time": "2024-07-01T16:12:20.051269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler cols: ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Item_Identifier_TE', 'Item_Type_TE', 'Outlet_Identifier_TE', 'Item_MRP_TE', 'Item_Weight_TE', 'Item_Visibility_TE', 'Item_Identifier_FE', 'Item_Type_FE', 'Outlet_Identifier_FE', 'Item_MRP_FE', 'Item_Weight_FE', 'Item_Visibility_FE', 'Item_Identifier_IE_Item_MRP', 'Item_Identifier_IE_Item_Weight', 'Item_Identifier_IE_Item_Visibility', 'Item_Type_IE_Item_MRP', 'Item_Type_IE_Item_Weight', 'Item_Type_IE_Item_Visibility', 'Outlet_Identifier_IE_Item_MRP', 'Outlet_Identifier_IE_Item_Weight', 'Outlet_Identifier_IE_Item_Visibility']\n",
      "lin_train_features.shape: (378428, 1617), lin_test_features.shape: (252286, 1617)\n"
     ]
    }
   ],
   "source": [
    "lin_drop_cols=[\n",
    "    \"id\", # ID\n",
    "    \"Item_Outlet_Sales\", # TARGET\n",
    "    \"Outlet_Establishment_Year\",\n",
    "    \"Item_Fat_Content\",\n",
    "    \"Outlet_Size\",\n",
    "    \"Outlet_Location_Type\",\n",
    "    \"Outlet_Type\",\n",
    "]\n",
    "\n",
    "# Prepare datasets for linear models\n",
    "lin_train_features = train_df.drop(columns=lin_drop_cols, errors=\"ignore\")\n",
    "target = train_df['Item_Outlet_Sales']\n",
    "\n",
    "# Handling missing values\n",
    "features_mean = lin_train_features.mean()\n",
    "lin_train_features = lin_train_features.fillna(features_mean)\n",
    "lin_test_features = test_df.drop(columns=lin_drop_cols, errors=\"ignore\").fillna(features_mean)\n",
    "\n",
    "ohe_cols = [\"Item_Identifier\", \"Item_Type\", \"Outlet_Identifier\", \"Item_MRP_class\"]\n",
    "lin_train_features = pd.get_dummies(lin_train_features, dummy_na=True, columns=ohe_cols)\n",
    "lin_test_features = pd.get_dummies(lin_test_features, dummy_na=True, columns=ohe_cols)\n",
    "\n",
    "ss_cols = [\"Item_Weight\", \"Item_Visibility\", \"Item_MRP\"] + \\\n",
    "            te_cols + [v + \"_FE\" for v in fe_cols] + ie_cols\n",
    "\n",
    "print(f\"StandardScaler cols: {ss_cols}\")\n",
    "for c in ss_cols:\n",
    "    ss = StandardScaler()\n",
    "    lin_train_features[c] = ss.fit_transform(lin_train_features[c].values.reshape(-1, 1))\n",
    "    lin_test_features[c] = ss.transform(lin_test_features[c].values.reshape(-1, 1))\n",
    "\n",
    "print(f\"lin_train_features.shape: {lin_train_features.shape}, lin_test_features.shape: {lin_test_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca9858",
   "metadata": {
    "papermill": {
     "duration": 0.009597,
     "end_time": "2024-07-01T16:12:22.044356",
     "exception": false,
     "start_time": "2024-07-01T16:12:22.034759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b778a003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T16:12:22.066527Z",
     "iopub.status.busy": "2024-07-01T16:12:22.065886Z",
     "iopub.status.idle": "2024-07-01T20:07:36.571170Z",
     "shell.execute_reply": "2024-07-01T20:07:36.569155Z"
    },
    "papermill": {
     "duration": 14114.519936,
     "end_time": "2024-07-01T20:07:36.574211",
     "exception": false,
     "start_time": "2024-07-01T16:12:22.054275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8625]\tvalid_0's rmse: 0.693247\tvalid_0's l2: 0.480591\n",
      "LGBM RMSLE: 0.693247018826365\n",
      "[0]\tvalidation_0-rmse:0.84844\n",
      "[1000]\tvalidation_0-rmse:0.69388\n",
      "[2000]\tvalidation_0-rmse:0.69347\n",
      "[2144]\tvalidation_0-rmse:0.69348\n",
      "XGB RMSLE: 0.6934479230552235\n",
      "HGBR RMSLE: 0.6947788394344074\n",
      "LR RMSLE: 0.6999175529399382\n",
      "RF RMSLE: 0.6960316723849539\n",
      "ENS RMSLE: 0.6922866308145504\n",
      "ENS weights: [ 0.51133622  0.3861403  -0.16600238  0.2957164  -0.00523254], bias: -0.15891990366682318\n",
      "LR ENS RMSLE: 0.69169530491441\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8454]\tvalid_0's rmse: 0.693683\tvalid_0's l2: 0.481197\n",
      "LGBM RMSLE: 0.6936834658800312\n",
      "[0]\tvalidation_0-rmse:0.85010\n",
      "[1000]\tvalidation_0-rmse:0.69441\n",
      "[2000]\tvalidation_0-rmse:0.69407\n",
      "[2280]\tvalidation_0-rmse:0.69404\n",
      "XGB RMSLE: 0.6940297799728722\n",
      "HGBR RMSLE: 0.6950693396969411\n",
      "LR RMSLE: 0.7014261693994034\n",
      "RF RMSLE: 0.6968808535605673\n",
      "ENS RMSLE: 0.6930893521644478\n",
      "ENS weights: [ 0.55068785  0.36191112 -0.11157419  0.2610442  -0.05469587], bias: -0.05320648489409052\n",
      "LR ENS RMSLE: 0.6925815074562206\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7744]\tvalid_0's rmse: 0.694206\tvalid_0's l2: 0.481922\n",
      "LGBM RMSLE: 0.6942060747882618\n",
      "[0]\tvalidation_0-rmse:0.85145\n",
      "[1000]\tvalidation_0-rmse:0.69490\n",
      "[1689]\tvalidation_0-rmse:0.69476\n",
      "XGB RMSLE: 0.6947108413018849\n",
      "HGBR RMSLE: 0.6957482367775661\n",
      "LR RMSLE: 0.7010167080999995\n",
      "RF RMSLE: 0.6967558044629283\n",
      "ENS RMSLE: 0.6934167761900879\n",
      "ENS weights: [ 0.66785791  0.18762244 -0.18616735  0.29678588  0.06163099], bias: -0.2031202816279576\n",
      "LR ENS RMSLE: 0.6928207249467577\n",
      "Fold 4/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8399]\tvalid_0's rmse: 0.696534\tvalid_0's l2: 0.48516\n",
      "LGBM RMSLE: 0.6965340969761401\n",
      "[0]\tvalidation_0-rmse:0.85102\n",
      "[1000]\tvalidation_0-rmse:0.69728\n",
      "[2000]\tvalidation_0-rmse:0.69697\n",
      "[2062]\tvalidation_0-rmse:0.69699\n",
      "XGB RMSLE: 0.6969454840982212\n",
      "HGBR RMSLE: 0.6977349287428772\n",
      "LR RMSLE: 0.7033189798697732\n",
      "RF RMSLE: 0.6993874177316443\n",
      "ENS RMSLE: 0.6957072919133518\n",
      "ENS weights: [ 0.52916261  0.27490593 -0.04696805  0.28460221 -0.03193293], bias: -0.07630766626765517\n",
      "LR ENS RMSLE: 0.6952722150726033\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7440]\tvalid_0's rmse: 0.69927\tvalid_0's l2: 0.488979\n",
      "LGBM RMSLE: 0.69927040738086\n",
      "[0]\tvalidation_0-rmse:0.85322\n",
      "[1000]\tvalidation_0-rmse:0.69988\n",
      "[2000]\tvalidation_0-rmse:0.69952\n",
      "[2111]\tvalidation_0-rmse:0.69950\n",
      "XGB RMSLE: 0.6994924334078777\n",
      "HGBR RMSLE: 0.7007476663205426\n",
      "LR RMSLE: 0.7061382956210831\n",
      "RF RMSLE: 0.7020641055716532\n",
      "ENS RMSLE: 0.6984595384821759\n",
      "ENS weights: [ 0.47341266  0.42676721 -0.14934167  0.28485421 -0.02163197], bias: -0.10264509806845012\n",
      "LR ENS RMSLE: 0.6979524498461664\n",
      "CPU times: user 4h 5min 23s, sys: 1min 34s, total: 4h 6min 57s\n",
      "Wall time: 3h 55min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_scores = []\n",
    "test_predictions = []\n",
    "feature_importance_values = np.zeros(tree_train_features.shape[1])\n",
    "\n",
    "ens_w_buf, ens_b_buf = [], []\n",
    "\n",
    "valid_x_buf = []\n",
    "valid_y_buf = []\n",
    "\n",
    "# Cross-validation loop\n",
    "for fold_i, (train_index, valid_index) in enumerate(kf.split(tree_train_features, target)):\n",
    "    print(f\"Fold {fold_i+1}/{kf.n_splits}\")\n",
    "    \n",
    "    X_train, X_valid = tree_train_features.iloc[train_index], tree_train_features.iloc[valid_index]\n",
    "    X_train_lin, X_valid_lin = lin_train_features.iloc[train_index], lin_train_features.iloc[valid_index]\n",
    "\n",
    "    y_train, y_valid = target.iloc[train_index], target.iloc[valid_index]\n",
    "\n",
    "    ens_p = []\n",
    "    test_p = []\n",
    "\n",
    "    # Training the LightGBM regressor\n",
    "    model = LGBMRegressor(\n",
    "        max_depth=26,\n",
    "        n_estimators=10000,\n",
    "        learning_rate=0.0021993020095881746,\n",
    "        num_leaves=217,\n",
    "        feature_fraction=0.6039737774032918,\n",
    "        bagging_fraction=0.8990670527363338,\n",
    "        min_split_gain=0.2865758698524692,\n",
    "        reg_alpha=0.20081754747685004,\n",
    "        reg_lambda=0.5795389842147277,\n",
    "        random_state=0,\n",
    "        n_jobs=N_JOBS,\n",
    "        verbose=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train,\n",
    "        eval_metric=\"rmse\",\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        callbacks=[lgb.early_stopping(200)]\n",
    "    )\n",
    "\n",
    "    # Update feature importance\n",
    "    feature_importance_values += model.feature_importances_ / kf.n_splits\n",
    "\n",
    "    # Predicting and calculating score on the validation set\n",
    "    y_pred = model.predict(X_valid, num_iteration=model._best_iteration)\n",
    "    ens_p.append(y_pred)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "\n",
    "    score = root_mean_squared_log_error(np.expm1(y_valid), y_pred)\n",
    "    print(f\"LGBM RMSLE: {score}\")\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    p = model.predict(tree_test_features, num_iteration=model._best_iteration)\n",
    "    test_p.append(p)\n",
    "\n",
    "    # Training the XGB regressor\n",
    "    model = XGBRegressor(\n",
    "        booster=\"gbtree\",\n",
    "        tree_method=\"hist\",\n",
    "        n_estimators=10000,\n",
    "        learning_rate=0.010124129393208042,\n",
    "        max_leaves=244,\n",
    "        subsample=0.9179406742270393,\n",
    "        colsample_bytree=0.7376895006776901,\n",
    "        reg_lambda=0.2913954318201704,\n",
    "        alpha=0.6967736207395685,\n",
    "        max_depth=13,\n",
    "        random_state=0,\n",
    "        n_jobs=N_JOBS,\n",
    "        early_stopping_rounds=200\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        verbose=1000,\n",
    "    )\n",
    "\n",
    "    # Predicting and calculating score on the validation set\n",
    "    y_pred = model.predict(X_valid, iteration_range=(0, model.best_iteration))\n",
    "    ens_p.append(y_pred)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    score = root_mean_squared_log_error(np.expm1(y_valid), y_pred)\n",
    "    print(f\"XGB RMSLE: {score}\")\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    p = model.predict(tree_test_features, iteration_range=(0, model.best_iteration))\n",
    "    test_p.append(p)\n",
    "\n",
    "    # HistGradientBoostingRegressor\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        max_iter=10000,\n",
    "        max_depth=25,\n",
    "        learning_rate=0.010820368051329765,\n",
    "        max_leaf_nodes=68,\n",
    "        max_features=0.6429655166020577,\n",
    "        l2_regularization=1.487687838498507,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=200,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    # Predicting and calculating score on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    ens_p.append(y_pred)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    score = root_mean_squared_log_error(np.expm1(y_valid), y_pred)\n",
    "    print(f\"HGBR RMSLE: {score}\")\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    p = model.predict(tree_test_features)\n",
    "    test_p.append(p)\n",
    "\n",
    "    # LR\n",
    "    model = LinearRegression( \n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_lin,\n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    # Predicting and calculating score on the validation set\n",
    "    y_pred = model.predict(X_valid_lin)\n",
    "    ens_p.append(y_pred)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    score = root_mean_squared_log_error(np.expm1(y_valid), y_pred)\n",
    "    print(f\"LR RMSLE: {score}\")\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    p = model.predict(lin_test_features)\n",
    "    test_p.append(p)\n",
    "\n",
    "    # RandomForestRegressor\n",
    "    model = RandomForestRegressor(\n",
    "        max_depth=15,\n",
    "        max_features=0.6462408415412457,\n",
    "        max_samples=0.7813502358248877,\n",
    "        n_estimators=358,\n",
    "        random_state=0,\n",
    "        n_jobs=N_JOBS\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train\n",
    "    )\n",
    "\n",
    "    # Predicting and calculating score on the validation set\n",
    "    y_pred = model.predict(X_valid)\n",
    "    ens_p.append(y_pred)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    score = root_mean_squared_log_error(np.expm1(y_valid), y_pred)\n",
    "    print(f\"RF RMSLE: {score}\")\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    p = model.predict(tree_test_features)\n",
    "    test_p.append(p)\n",
    "\n",
    "    # Evaluate ensemble\n",
    "    ens_preds = np.mean(ens_p, axis=0)\n",
    "    ens_preds = np.expm1(ens_preds)\n",
    "    ens_preds = np.clip(ens_preds, 0, None)\n",
    "    score = root_mean_squared_log_error(np.expm1(y_valid), ens_preds)\n",
    "    print(f\"ENS RMSLE: {score}\")\n",
    "\n",
    "    X_ens = np.array(ens_p).transpose()\n",
    "    ens_model = LinearRegression(n_jobs=N_JOBS)\n",
    "    ens_model.fit(X_ens, y_valid)\n",
    "    ens_w = ens_model.coef_\n",
    "    ens_b = ens_model.intercept_\n",
    "    print(f\"ENS weights: {ens_w}, bias: {ens_b}\")\n",
    "    ens_w_buf.append(ens_w)\n",
    "    ens_b_buf.append(ens_b)\n",
    "\n",
    "    ens_preds = ens_model.predict(X_ens)\n",
    "    ens_preds = np.expm1(ens_preds)\n",
    "    ens_preds = np.clip(ens_preds, 0, None)\n",
    "    score = root_mean_squared_log_error(np.expm1(y_valid), ens_preds)\n",
    "    print(f\"LR ENS RMSLE: {score}\")\n",
    "    fold_scores.append(score)\n",
    "\n",
    "    valid_x_buf.append(X_ens)\n",
    "    valid_y_buf.append(y_valid)\n",
    "\n",
    "    test_predictions.append(test_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92f71685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T20:07:36.604793Z",
     "iopub.status.busy": "2024-07-01T20:07:36.604419Z",
     "iopub.status.idle": "2024-07-01T20:07:36.610465Z",
     "shell.execute_reply": "2024-07-01T20:07:36.609530Z"
    },
    "papermill": {
     "duration": 0.023971,
     "end_time": "2024-07-01T20:07:36.612511",
     "exception": false,
     "start_time": "2024-07-01T20:07:36.588540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSLE: 0.6940644404472316, Std of RMSLE: 0.0022774572798067183\n"
     ]
    }
   ],
   "source": [
    "average_score = np.mean(fold_scores)\n",
    "std_score = np.std(fold_scores)\n",
    "print(f\"Average RMSLE: {average_score}, Std of RMSLE: {std_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490d010",
   "metadata": {
    "papermill": {
     "duration": 0.013682,
     "end_time": "2024-07-01T20:07:36.640202",
     "exception": false,
     "start_time": "2024-07-01T20:07:36.626520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Combine predictions with Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1caab82c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T20:07:36.669930Z",
     "iopub.status.busy": "2024-07-01T20:07:36.669550Z",
     "iopub.status.idle": "2024-07-01T20:07:37.104378Z",
     "shell.execute_reply": "2024-07-01T20:07:37.102933Z"
    },
    "papermill": {
     "duration": 0.452301,
     "end_time": "2024-07-01T20:07:37.106755",
     "exception": false,
     "start_time": "2024-07-01T20:07:36.654454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ensembling LR model\n",
      "valid_x_buf.shape: (378428, 5), valid_y_buf.shape: (378428,)\n",
      "ENS Model weights: [ 0.54318574  0.33390037 -0.13402332  0.28448649 -0.01164513], bias: -0.11687988031950436\n",
      "LR ENS RMSLE: 0.6940962480552789\n",
      "Test 0 X shape: (252286, 5)\n",
      "Test 0 preds shape: (252286,)\n",
      "Test 1 X shape: (252286, 5)\n",
      "Test 1 preds shape: (252286,)\n",
      "Test 2 X shape: (252286, 5)\n",
      "Test 2 preds shape: (252286,)\n",
      "Test 3 X shape: (252286, 5)\n",
      "Test 3 preds shape: (252286,)\n",
      "Test 4 X shape: (252286, 5)\n",
      "Test 4 preds shape: (252286,)\n",
      "test_predictions.shape: (252286,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ensembling LR model\")\n",
    "ens_model = LinearRegression(n_jobs=N_JOBS)\n",
    "valid_x_buf = np.concatenate(valid_x_buf, axis=0)\n",
    "valid_y_buf = np.concatenate(valid_y_buf, axis=0)\n",
    "print(f\"valid_x_buf.shape: {valid_x_buf.shape}, valid_y_buf.shape: {valid_y_buf.shape}\")\n",
    "ens_model.fit(valid_x_buf, valid_y_buf)\n",
    "print(f\"ENS Model weights: {ens_model.coef_}, bias: {ens_model.intercept_}\")\n",
    "\n",
    "valid_p = ens_model.predict(valid_x_buf)\n",
    "valid_p = np.expm1(valid_p)\n",
    "valid_p = np.clip(valid_p, 0, None)\n",
    "average_score = root_mean_squared_log_error(np.expm1(valid_y_buf), valid_p)\n",
    "print(f\"LR ENS RMSLE: {average_score}\")\n",
    "\n",
    "\n",
    "for i, tp in enumerate(test_predictions):\n",
    "    tp = np.array(tp).transpose()\n",
    "    print(f\"Test {i} X shape: {tp.shape}\")\n",
    "    tp = ens_model.predict(tp)\n",
    "    print(f\"Test {i} preds shape: {tp.shape}\")\n",
    "    test_predictions[i] = tp\n",
    "test_predictions = np.mean(test_predictions, axis=0)\n",
    "test_predictions = np.expm1(test_predictions)\n",
    "test_predictions = np.clip(test_predictions, 0, None)\n",
    "print(f\"test_predictions.shape: {test_predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b91122",
   "metadata": {
    "papermill": {
     "duration": 0.014163,
     "end_time": "2024-07-01T20:07:37.135584",
     "exception": false,
     "start_time": "2024-07-01T20:07:37.121421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Identify top K important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df52baa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T20:07:37.165599Z",
     "iopub.status.busy": "2024-07-01T20:07:37.165125Z",
     "iopub.status.idle": "2024-07-01T20:07:37.177973Z",
     "shell.execute_reply": "2024-07-01T20:07:37.176845Z"
    },
    "papermill": {
     "duration": 0.030365,
     "end_time": "2024-07-01T20:07:37.180162",
     "exception": false,
     "start_time": "2024-07-01T20:07:37.149797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Important Features:\n",
      "                                 feature  importance\n",
      "9                            Item_MRP_TE    120044.4\n",
      "15                           Item_MRP_FE    109686.2\n",
      "2                        Item_Visibility    105434.6\n",
      "4                               Item_MRP    105136.0\n",
      "11                    Item_Visibility_TE    100206.4\n",
      "10                        Item_Weight_TE     94601.8\n",
      "6                     Item_Identifier_TE     91258.0\n",
      "18           Item_Identifier_IE_Item_MRP     90031.4\n",
      "20    Item_Identifier_IE_Item_Visibility     86034.6\n",
      "19        Item_Identifier_IE_Item_Weight     84884.4\n",
      "1                            Item_Weight     80452.4\n",
      "17                    Item_Visibility_FE     76003.4\n",
      "12                    Item_Identifier_FE     71442.8\n",
      "16                        Item_Weight_FE     70657.6\n",
      "0                        Item_Identifier     69486.8\n",
      "8                   Outlet_Identifier_TE     66436.8\n",
      "26  Outlet_Identifier_IE_Item_Visibility     52568.0\n",
      "22              Item_Type_IE_Item_Weight     44868.2\n",
      "25      Outlet_Identifier_IE_Item_Weight     44420.2\n",
      "21                 Item_Type_IE_Item_MRP     41508.4\n",
      "24         Outlet_Identifier_IE_Item_MRP     41393.6\n",
      "23          Item_Type_IE_Item_Visibility     39888.8\n",
      "7                           Item_Type_TE     34232.8\n",
      "3                              Item_Type     11133.8\n",
      "13                          Item_Type_FE     10913.2\n",
      "14                  Outlet_Identifier_FE      7935.6\n",
      "5                      Outlet_Identifier      5644.2\n"
     ]
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame({\n",
    "    'feature': tree_train_features.columns,\n",
    "    'importance': feature_importance_values\n",
    "}).sort_values(by='importance', ascending=False).head(40)\n",
    "\n",
    "print(\"Top Important Features:\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df63b9cd",
   "metadata": {
    "papermill": {
     "duration": 0.014112,
     "end_time": "2024-07-01T20:07:37.209026",
     "exception": false,
     "start_time": "2024-07-01T20:07:37.194914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare the submission file with predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60f96c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-01T20:07:37.240005Z",
     "iopub.status.busy": "2024-07-01T20:07:37.239056Z",
     "iopub.status.idle": "2024-07-01T20:07:37.793682Z",
     "shell.execute_reply": "2024-07-01T20:07:37.792654Z"
    },
    "papermill": {
     "duration": 0.572471,
     "end_time": "2024-07-01T20:07:37.795892",
     "exception": false,
     "start_time": "2024-07-01T20:07:37.223421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id  Item_Outlet_Sales\n",
      "0  378428        3008.187088\n",
      "1  378429        2733.251288\n",
      "2  378430        2212.245846\n",
      "3  378431        1715.024614\n",
      "4  378432        1508.334617\n",
      "5  378433        1960.262250\n",
      "6  378434        2333.657808\n",
      "7  378435        2349.407367\n",
      "8  378436        1605.060827\n",
      "9  378437        2111.172706\n",
      "Submission file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Item_Outlet_Sales': test_predictions\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission_file_path = 'submission.csv'\n",
    "submission.to_csv(submission_file_path, index=False)\n",
    "print(submission.head(10))\n",
    "\n",
    "print(\"Submission file saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423d16d",
   "metadata": {
    "papermill": {
     "duration": 0.014279,
     "end_time": "2024-07-01T20:07:37.824891",
     "exception": false,
     "start_time": "2024-07-01T20:07:37.810612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8765512,
     "sourceId": 77807,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14161.27726,
   "end_time": "2024-07-01T20:07:38.684052",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-01T16:11:37.406792",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
